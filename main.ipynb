{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from typing import Dict\n",
    "from langchain_community.adapters.openai import convert_message_to_dict\n",
    "from langchain_core.messages import AIMessage\n",
    "from typing import List\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "import re\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GROQ_API_KEY=os.getenv(\"groq_api_key\")\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "llm=ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Agents functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prompt from an external file\n",
    "with open(\"prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    SALES_EXECUTIVE_PROMPT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sales_agent(messages: List[dict]) -> dict:\n",
    "\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": SALES_EXECUTIVE_PROMPT,\n",
    "    }\n",
    "\n",
    "    messages = [system_message] + messages \n",
    "\n",
    "    response: AIMessage = llm.invoke(messages)\n",
    "\n",
    "    return {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": response.content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated user\n",
    "\n",
    "system_prompt_template = \"\"\"You are a customer. \\\n",
    "You are interacting with a user who is a customer support person. \\\n",
    "\n",
    "{instructions}\n",
    "\n",
    "When you are finished with the conversation, respond with a single word 'FINISHED'\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt_template),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "instructions = \"\"\"Your name is Carryminati. You want to buy a bike. \\\n",
    "You want to inquire about it. \\\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt.partial(name=\"Carryminati\", instructions=instructions)\n",
    "\n",
    "simulated_user = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_response(simulated_user_message:str, chatbot_message:str) -> Dict:\n",
    "    \"\"\"Evaluate the Sales Agent's response based on key metrics.\"\"\"\n",
    "    \n",
    "    evaluation_prompt = f\"\"\"\n",
    "    You are an Evaluator AI that assesses responses from a Sales Agent based on company policies.\n",
    "\n",
    "    User Query: {simulated_user_message}\n",
    "    Sales Agent Response: {chatbot_message}\n",
    "\n",
    "    Evaluate the response on:\n",
    "    - Accuracy (1-5): Did the agent provide accurate information without errors?\n",
    "    - Completeness (1-5): Did the agent cover all necessary details and follow all provided rules?\n",
    "    - Compliance (1-5): Did the agent follow company policies (e.g., not providing prices, referring to the correct contacts)?\n",
    "    - Engagement (1-5): Did the agent engage with the customer in a friendly and helpful manner?\n",
    "\n",
    "    Provide a short feedback summary.\n",
    "\n",
    "    Output as JSON:\n",
    "    {{\n",
    "        \"accuracy\": int,\n",
    "        \"completeness\": int,\n",
    "        \"compliance\": int,\n",
    "        \"engagement\": int,\n",
    "        \"feedback\": \"string\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    eval_response = llm.invoke([SystemMessage(content=evaluation_prompt)])\n",
    "    return eval_response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sales_agent_node(state):\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    messages = [convert_message_to_dict(m) for m in messages]\n",
    "\n",
    "    chat_bot_response = sales_agent(messages)\n",
    "    chat_message = AIMessage(content=chat_bot_response[\"content\"])\n",
    "    \n",
    "    last_user_message = messages[-1][\"content\"]\n",
    "    evaluation = evaluate_response(last_user_message, chat_message.content)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [chat_message],\n",
    "        \"evaluation\": evaluation\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _swap_roles(messages):\n",
    "\n",
    "    new_messages = [] \n",
    "\n",
    "    for m in messages:\n",
    "        if isinstance(m, AIMessage):  \n",
    "            new_messages.append(HumanMessage(content=m.content))  # AI → Human\n",
    "        else:\n",
    "            new_messages.append(AIMessage(content=m.content))  # Human → AI\n",
    "    \n",
    "    return new_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_user_node(state):\n",
    "\n",
    "    messages = state[\"messages\"] \n",
    "\n",
    "    new_messages = _swap_roles(messages) \n",
    "\n",
    "    response = simulated_user.invoke({\"messages\": new_messages})  \n",
    "\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=response.content)]  \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 8:\n",
    "        return \"end\"\n",
    "    elif messages[-1].content == \"FINISHED\":\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    evaluation: dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"user\", simulated_user_node)\n",
    "graph_builder.add_node(\"chat_bot\", sales_agent_node)\n",
    "graph_builder.add_edge(\"user\", \"chat_bot\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chat_bot\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"continue\": \"user\",\n",
    "    },\n",
    ")\n",
    "graph_builder.add_edge(START, \"user\")\n",
    "simulation = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(simulation.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating user queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_message(message):\n",
    "    \"\"\"Convert message objects into dictionaries for JSON serialization.\"\"\"\n",
    "    if isinstance(message, (list, tuple)):\n",
    "        return [serialize_message(m) for m in message]\n",
    "    if hasattr(message, \"__dict__\"):\n",
    "        return message.__dict__\n",
    "    return message  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in simulation.stream({\"messages\": [], \"evaluation\": {}}):\n",
    "    if END not in chunk:\n",
    "        chunk_serializable = {}\n",
    "        for key, value in chunk.items():\n",
    "            if isinstance(value, dict) and 'messages' in value:\n",
    "                chunk_serializable[key] = {\n",
    "                    'messages': [{\n",
    "                        'content': msg.content,\n",
    "                        'type': msg.__class__.__name__\n",
    "                    } for msg in value['messages']]\n",
    "                }\n",
    "            else:\n",
    "                chunk_serializable[key] = value\n",
    "        print(json.dumps(chunk_serializable, indent=4)) \n",
    "        \n",
    "        evaluation_raw = chunk.get(\"chat_bot\", {}).get(\"evaluation\")\n",
    "        if evaluation_raw:\n",
    "            try:\n",
    "                evaluation_cleaned = re.sub(r\"^```json\\n|\\n```$\", \"\", evaluation_raw.strip())\n",
    "\n",
    "                evaluation_data = json.loads(evaluation_cleaned)\n",
    "                \n",
    "                print(\"Evaluation:\")\n",
    "                for key, value in evaluation_data.items():\n",
    "                    if isinstance(value, str):\n",
    "                        print(f\"{key.capitalize()}:\")\n",
    "                        print(textwrap.fill(value, width=80)) \n",
    "                    else:\n",
    "                        print(f\"{key.capitalize()}: {value}\")\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"Error: Invalid JSON in evaluation\", e)\n",
    "\n",
    "        print(\"----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking custom queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_custom_question(user_input: str):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_input}]\n",
    "\n",
    "    chat_bot_response = sales_agent(messages)\n",
    "    chat_message = AIMessage(content=chat_bot_response[\"content\"])\n",
    "\n",
    "    evaluation = evaluate_response(user_input, chat_message.content)\n",
    "\n",
    "    return {\n",
    "        \"chatbot_response\": chat_message.content,\n",
    "        \"evaluation\": evaluation\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_question = \"Can you tell me price of bike Speed Twin 1200?\"\n",
    "response_data = ask_custom_question(custom_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chatbot Response:\")\n",
    "print(response_data[\"chatbot_response\"])\n",
    "print(\"\\nEvaluation:\")\n",
    "print(response_data[\"evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
